name: "Mastodon Docker - BoringCache"

on:
  workflow_dispatch:
  pull_request:
    paths:
      - ".github/workflows/mastodon-docker-boringcache.yml"
      - ".github/workflows/mastodon-docker-actions-cache.yml"
      - "dockerfiles/mastodon/**"
      - "scripts/**"
  schedule:
    - cron: "0 6 * * 0"

permissions:
  contents: read
  actions: read

env:
  PROJECT_REPO: mastodon/mastodon
  PROJECT_REF: "0b66e744263a4af1f14d03886ea2a9da4ca156db"
  BENCHMARK_ID: mastodon-docker
  BENCHMARK_WORKSPACE: boringcache/benchmarks

jobs:
  docker-build:
    name: Docker Build (BoringCache, cold+warm)
    runs-on: ubuntu-latest
    timeout-minutes: 120
    steps:
      - name: Checkout target repo
        uses: actions/checkout@v4
        with:
          repository: ${{ env.PROJECT_REPO }}
          ref: ${{ env.PROJECT_REF }}

      - name: Checkout benchmark config
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository }}
          ref: ${{ github.sha }}
          path: .benchmark-config

      - name: Setup BoringCache CLI
        uses: boringcache/setup-boringcache@v1
        with:
          token: ${{ secrets.BORINGCACHE_API_TOKEN }}
          platform: linux-amd64
        env:
          BORINGCACHE_API_TOKEN: ${{ secrets.BORINGCACHE_API_TOKEN }}

      - name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v3
        with:
          driver-opts: |
            network=host

      - name: Prepare benchmark build inputs
        id: scope
        run: |
          cp "$(which boringcache)" ./boringcache-bin-real
          cat > ./boringcache-bin-noop <<'SH'
          #!/usr/bin/env sh
          exit 0
          SH
          chmod +x ./boringcache-bin-real ./boringcache-bin-noop
          cp ./boringcache-bin-real ./boringcache-bin
          echo '!boringcache-bin' >> .dockerignore
          cp .benchmark-config/dockerfiles/mastodon/Dockerfile.boringcache Dockerfile.boringcache

          cache_scope="${BENCHMARK_ID}r${GITHUB_RUN_ID}a${GITHUB_RUN_ATTEMPT}"
          run_suffix="r${GITHUB_RUN_ID}a${GITHUB_RUN_ATTEMPT}"
          libvips_tag="mastodon-libvips-8.18.0"
          ffmpeg_tag="mastodon-ffmpeg-8.0"
          gems_tag="mastodon-gems"
          yarn_tag="mastodon-yarn"
          libvips_cold_tag="${libvips_tag}-${run_suffix}"
          ffmpeg_cold_tag="${ffmpeg_tag}-${run_suffix}"
          gems_cold_tag="${gems_tag}-${run_suffix}"
          yarn_cold_tag="${yarn_tag}-${run_suffix}"
          tags_csv="${libvips_tag},${ffmpeg_tag},${gems_tag},${yarn_tag},${libvips_cold_tag},${ffmpeg_cold_tag},${gems_cold_tag},${yarn_cold_tag},${cache_scope}"
          echo "cache_scope=${cache_scope}" >> "$GITHUB_OUTPUT"
          echo "libvips_tag=${libvips_tag}" >> "$GITHUB_OUTPUT"
          echo "ffmpeg_tag=${ffmpeg_tag}" >> "$GITHUB_OUTPUT"
          echo "gems_tag=${gems_tag}" >> "$GITHUB_OUTPUT"
          echo "yarn_tag=${yarn_tag}" >> "$GITHUB_OUTPUT"
          echo "libvips_cold_tag=${libvips_cold_tag}" >> "$GITHUB_OUTPUT"
          echo "ffmpeg_cold_tag=${ffmpeg_cold_tag}" >> "$GITHUB_OUTPUT"
          echo "gems_cold_tag=${gems_cold_tag}" >> "$GITHUB_OUTPUT"
          echo "yarn_cold_tag=${yarn_cold_tag}" >> "$GITHUB_OUTPUT"
          echo "tags_csv=${tags_csv}" >> "$GITHUB_OUTPUT"
          cat > ./run-boringcache-build.sh <<'SH'
          #!/usr/bin/env bash
          set -euo pipefail

          proxy_port=5000
          proxy_log="$(mktemp /tmp/boringcache-proxy.XXXXXX.log)"
          build_log="$(mktemp /tmp/boringcache-build.XXXXXX.log)"
          max_attempts=4
          cache_export_pattern='expected sha256:.*got sha256:e3b0|error writing layer blob|400 Bad Request|broken pipe'

          mode="${1:-full}"
          proxy_pid=""

          start_proxy() {
            : > "$proxy_log"
            RUST_LOG=debug boringcache docker-registry "$BENCHMARK_WORKSPACE" --host 0.0.0.0 --port "$proxy_port" --no-git --verbose > "$proxy_log" 2>&1 &
            proxy_pid=$!
          }

          stop_proxy() {
            if [[ -n "${proxy_pid:-}" ]] && kill -0 "$proxy_pid" >/dev/null 2>&1; then
              kill "$proxy_pid" >/dev/null 2>&1 || true
              wait "$proxy_pid" 2>/dev/null || true
            fi
            proxy_pid=""
          }

          wait_proxy_ready() {
            local ready=0
            for _ in $(seq 1 60); do
              code="$(curl -s -o /dev/null -w '%{http_code}' "http://127.0.0.1:${proxy_port}/v2/" || true)"
              if [[ "$code" == "200" || "$code" == "401" ]]; then
                ready=1
                break
              fi
              sleep 1
            done
            [[ "$ready" -eq 1 ]]
          }

          cleanup() {
            stop_proxy
          }
          trap cleanup EXIT

          attempt=1
          while true; do
            cache_args=()
            if [[ "$mode" == "full" ]]; then
              cache_args=(
                --cache-from "type=registry,ref=127.0.0.1:${proxy_port}/${CACHE_SCOPE},registry.insecure=true"
                --cache-to "type=registry,ref=127.0.0.1:${proxy_port}/${CACHE_SCOPE},mode=max,ignore-error=true,registry.insecure=true"
              )
            elif [[ "$mode" == "internal-only" ]]; then
              # Disable Docker layer cache for a full stale rebuild.
              cache_args=(--no-cache)
            elif [[ "$mode" == "internal-target" ]]; then
              # Isolate internal dependency/output cache impact without final-image OS package work.
              cache_args=(--no-cache --target precompiler)
            else
              echo "Unknown build mode: $mode" >&2
              exit 1
            fi

            if [[ "$mode" == "full" ]]; then
              cp ./boringcache-bin-noop ./boringcache-bin
            else
              cp ./boringcache-bin-real ./boringcache-bin
            fi

            start_proxy
            if ! wait_proxy_ready; then
              echo "Registry proxy did not become ready (attempt ${attempt}/${max_attempts})" >&2
              tail -n 200 "$proxy_log" || true
              if [[ "$attempt" -ge "$max_attempts" ]]; then
                exit 1
              fi
              stop_proxy
              attempt=$((attempt + 1))
              sleep 3
              continue
            fi

            : > "$build_log"
            set +e
            DOCKER_BUILDKIT=1 docker buildx build \
              --builder "$BUILDER" \
              --file Dockerfile.boringcache \
              --tag "$IMAGE_TAG" \
              --progress=plain \
              "${cache_args[@]}" \
              --secret id=boringcache_token,env=BORINGCACHE_API_TOKEN \
              --build-arg BORINGCACHE_WORKSPACE="$BENCHMARK_WORKSPACE" \
              --build-arg BORINGCACHE_TAG_LIBVIPS="$BORINGCACHE_TAG_LIBVIPS" \
              --build-arg BORINGCACHE_TAG_FFMPEG="$BORINGCACHE_TAG_FFMPEG" \
              --build-arg BORINGCACHE_TAG_GEMS="$BORINGCACHE_TAG_GEMS" \
              --build-arg BORINGCACHE_TAG_YARN="$BORINGCACHE_TAG_YARN" \
              . 2>&1 | tee "$build_log"
            status=${PIPESTATUS[0]}
            set -e

            if [[ "$status" -eq 0 ]]; then
              if [[ "$mode" == "full" ]] && grep -Eq "$cache_export_pattern" "$build_log"; then
                stop_proxy
                if [[ "$attempt" -lt "$max_attempts" ]]; then
                  echo "Build succeeded but cache export was degraded (attempt ${attempt}/${max_attempts}); retrying to self-heal cache..." >&2
                  attempt=$((attempt + 1))
                  sleep $((attempt * 5))
                  continue
                fi
                echo "Build succeeded but cache export still degraded after ${max_attempts} attempts; continuing run with best-effort cache state." >&2
              fi
              break
            fi

            stop_proxy

            if [[ "$attempt" -ge "$max_attempts" ]]; then
              echo "Build (${mode}) failed after ${max_attempts} attempts" >&2
              tail -n 200 "$build_log" || true
              tail -n 400 "$proxy_log" || true
              exit "$status"
            fi

            if grep -Eq "$cache_export_pattern" "$build_log"; then
              echo "Detected registry blob finalize mismatch (attempt ${attempt}/${max_attempts}); restarting proxy and retrying..." >&2
            else
              echo "Build (${mode}) failed (attempt ${attempt}/${max_attempts}); retrying..." >&2
            fi

            attempt=$((attempt + 1))
            sleep $((attempt * 5))
          done
          SH
          chmod +x ./run-boringcache-build.sh

      - name: Run cold build
        id: cold_build
        env:
          BORINGCACHE_API_TOKEN: ${{ secrets.BORINGCACHE_API_TOKEN }}
          BUILDER: ${{ steps.buildx.outputs.name }}
          CACHE_SCOPE: ${{ steps.scope.outputs.cache_scope }}
          BORINGCACHE_TAG_LIBVIPS: ${{ steps.scope.outputs.libvips_cold_tag }}
          BORINGCACHE_TAG_FFMPEG: ${{ steps.scope.outputs.ffmpeg_cold_tag }}
          BORINGCACHE_TAG_GEMS: ${{ steps.scope.outputs.gems_cold_tag }}
          BORINGCACHE_TAG_YARN: ${{ steps.scope.outputs.yarn_cold_tag }}
          IMAGE_TAG: mastodon-benchmark:latest
        run: |
          set -euo pipefail
          start="$(date +%s)"
          ./run-boringcache-build.sh
          end="$(date +%s)"
          echo "seconds=$((end - start))" >> "$GITHUB_OUTPUT"

      - name: Run warm build 1
        id: warm1_build
        env:
          BORINGCACHE_API_TOKEN: ${{ secrets.BORINGCACHE_API_TOKEN }}
          BUILDER: ${{ steps.buildx.outputs.name }}
          CACHE_SCOPE: ${{ steps.scope.outputs.cache_scope }}
          BORINGCACHE_TAG_LIBVIPS: ${{ steps.scope.outputs.libvips_cold_tag }}
          BORINGCACHE_TAG_FFMPEG: ${{ steps.scope.outputs.ffmpeg_cold_tag }}
          BORINGCACHE_TAG_GEMS: ${{ steps.scope.outputs.gems_cold_tag }}
          BORINGCACHE_TAG_YARN: ${{ steps.scope.outputs.yarn_cold_tag }}
          IMAGE_TAG: mastodon-benchmark:latest
        run: |
          set -euo pipefail
          start="$(date +%s)"
          ./run-boringcache-build.sh
          end="$(date +%s)"
          echo "seconds=$((end - start))" >> "$GITHUB_OUTPUT"

      - name: Run warm build 2
        id: warm2_build
        env:
          BORINGCACHE_API_TOKEN: ${{ secrets.BORINGCACHE_API_TOKEN }}
          BUILDER: ${{ steps.buildx.outputs.name }}
          CACHE_SCOPE: ${{ steps.scope.outputs.cache_scope }}
          BORINGCACHE_TAG_LIBVIPS: ${{ steps.scope.outputs.libvips_cold_tag }}
          BORINGCACHE_TAG_FFMPEG: ${{ steps.scope.outputs.ffmpeg_cold_tag }}
          BORINGCACHE_TAG_GEMS: ${{ steps.scope.outputs.gems_cold_tag }}
          BORINGCACHE_TAG_YARN: ${{ steps.scope.outputs.yarn_cold_tag }}
          IMAGE_TAG: mastodon-benchmark:latest
        run: |
          set -euo pipefail
          start="$(date +%s)"
          ./run-boringcache-build.sh
          end="$(date +%s)"
          echo "seconds=$((end - start))" >> "$GITHUB_OUTPUT"

      - name: Run stale Docker cache build (full build, no layer cache)
        id: stale_docker_build
        env:
          BORINGCACHE_API_TOKEN: ${{ secrets.BORINGCACHE_API_TOKEN }}
          BUILDER: ${{ steps.buildx.outputs.name }}
          CACHE_SCOPE: ${{ steps.scope.outputs.cache_scope }}
          BORINGCACHE_TAG_LIBVIPS: ${{ steps.scope.outputs.libvips_tag }}
          BORINGCACHE_TAG_FFMPEG: ${{ steps.scope.outputs.ffmpeg_tag }}
          BORINGCACHE_TAG_GEMS: ${{ steps.scope.outputs.gems_tag }}
          BORINGCACHE_TAG_YARN: ${{ steps.scope.outputs.yarn_tag }}
          IMAGE_TAG: mastodon-benchmark:latest
        run: |
          set -euo pipefail
          start="$(date +%s)"
          ./run-boringcache-build.sh internal-only
          end="$(date +%s)"
          echo "seconds=$((end - start))" >> "$GITHUB_OUTPUT"

      - name: Run internal cache warm build (targeted)
        id: internal_only_build
        env:
          BORINGCACHE_API_TOKEN: ${{ secrets.BORINGCACHE_API_TOKEN }}
          BUILDER: ${{ steps.buildx.outputs.name }}
          CACHE_SCOPE: ${{ steps.scope.outputs.cache_scope }}
          BORINGCACHE_TAG_LIBVIPS: ${{ steps.scope.outputs.libvips_tag }}
          BORINGCACHE_TAG_FFMPEG: ${{ steps.scope.outputs.ffmpeg_tag }}
          BORINGCACHE_TAG_GEMS: ${{ steps.scope.outputs.gems_tag }}
          BORINGCACHE_TAG_YARN: ${{ steps.scope.outputs.yarn_tag }}
          IMAGE_TAG: mastodon-benchmark:latest
        run: |
          set -euo pipefail
          start="$(date +%s)"
          ./run-boringcache-build.sh internal-target
          end="$(date +%s)"
          echo "seconds=$((end - start))" >> "$GITHUB_OUTPUT"

      - name: Measure BoringCache storage usage
        id: cache_size
        env:
          BORINGCACHE_API_TOKEN: ${{ secrets.BORINGCACHE_API_TOKEN }}
        run: |
          tags_csv="${{ steps.scope.outputs.tags_csv }}"
          bytes="$(.benchmark-config/scripts/sum-boringcache-check-sizes.sh "$BENCHMARK_WORKSPACE" "$tags_csv")"
          echo "bytes=${bytes}" >> "$GITHUB_OUTPUT"

      - name: Write benchmark artifacts
        id: artifact_files
        run: |
          .benchmark-config/scripts/write-benchmark-artifacts.sh \
            --benchmark "$BENCHMARK_ID" \
            --strategy "boringcache" \
            --project-repo "$PROJECT_REPO" \
            --project-ref "$PROJECT_REF" \
            --cold-seconds "${{ steps.cold_build.outputs.seconds }}" \
            --warm1-seconds "${{ steps.warm1_build.outputs.seconds }}" \
            --warm2-seconds "${{ steps.warm2_build.outputs.seconds }}" \
            --stale-docker-seconds "${{ steps.stale_docker_build.outputs.seconds }}" \
            --internal-only-warm-seconds "${{ steps.internal_only_build.outputs.seconds }}" \
            --cache-storage-bytes "${{ steps.cache_size.outputs.bytes }}" \
            --cache-storage-source "boringcache-check" \
            --bytes-uploaded "${{ steps.cache_size.outputs.bytes }}" \
            --hit-behavior-note "Cold+warm runs mount a no-op boringcache binary (no internal save/restore), stale/internal metrics mount real boringcache with stable lockfile/version keyed tags. Stale Docker run uses --no-cache full build, internal-only run uses --no-cache --target precompiler"

      - name: Upload benchmark artifacts
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-${{ env.BENCHMARK_ID }}-boringcache
          path: |
            ${{ steps.artifact_files.outputs.json_path }}
            ${{ steps.artifact_files.outputs.md_path }}
          if-no-files-found: error

      - name: Publish summary
        run: cat "${{ steps.artifact_files.outputs.md_path }}" >> "$GITHUB_STEP_SUMMARY"
